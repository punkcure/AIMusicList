<!--
 * @Author: madan madan@migu.cn
 * @Date: 2023-03-10 17:37:08
 * @LastEditors: madan madan@migu.cn
 * @LastEditTime: 2023-04-14 14:41:45
 * @FilePath: \AIMusicList\README.md
 * @Description: 这是默认设置,请设置`customMade`, 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
-->

## Speech
| Year  | name                                                                                                                                                                              | Paper                                            | Brief | assese                                                          |   
| ----- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2020| [SymphonyNet](https://github.com/symphonynet/SymphonyNet)                                                             |   |    交响乐多轨 可用于其他类型 无数据                                                                          | -                                                                                                                                                                   |

## Symbol Music Generation 

| Year  | name                                                                                                                                                                              | Paper                                            | Brief | assese                                                          |   
| ----- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2023| [Multitrack Music Transformer](https://github.com/salu133445/mmt)                                                             | [arXiv](https://arxiv.org/pdf/2207.06983.pdf)    |    多轨tranformer 数据集：Symbolic orchestral database (SOD).                                                                           | -                                                                                                                                                                   |
| 2023| [Multitrack Music Transformer](https://github.com/salu133445/mmt)                                                             | [arXiv](https://arxiv.org/pdf/2207.06983.pdf)    |    多轨tranformer 数据集：Symbolic orchestral database (SOD).                                                                           | -                                                                                                                                                                   |
| 2020| [MuseMorphose: Full-Song and Fine-Grained Piano Music Style Transfer with One Transformer VAE](https://github.com/openai/jukebox)                                                       | 2022 TASLP [arXiv](https://arxiv.org/pdf/2105.04090.pdf)  [demo](https://slseanwu.github.io/site-musemorphose/)|    perform style transfer on long musical pieces, while allowing users to control musical attributes down to the bar level                                                                           | -                                                                                                                                                                   |
| 2020| [MuseMorphose: Full-Song and Fine-Grained Piano Music Style Transfer with One Transformer VAE](https://github.com/openai/jukebox)                                                       | 2022 TASLP [arXiv](https://arxiv.org/pdf/2105.04090.pdf)  [demo](https://slseanwu.github.io/site-musemorphose/)|    perform style transfer on long musical pieces, while allowing users to control musical attributes down to the bar level                                                                           | -                                                                                                                                                                   |
| 2022| [Lyric-Melody-Generation](https://github.com/benfenison/Lyric-Melody-Generation)                                                       | |                                                                                | -                                                                                                                                                                   |
| 2020| [Jukebox: A Generative Model for Music](https://github.com/openai/jukebox)                                                       | [arXiv](https://arxiv.org/pdf/2005.00341.pdf)  |                                                                                | -                                                                                                                                                                   |
| 2019| [Music Transformer tf2.0](https://github.com/jason9693/MusicTransformer-tensorflow2.0)  [pytorch](https://github.com/jason9693/MusicTransformer-pytorch)                                                        |2019 ICLR [arXiv](https://arxiv.org/pdf/1809.04281.pdf)  |                                                                                | -                                                                                                                                                                   |
| 2020| [Pop music transformer](https://github.com/YatingMusic/remi)                                                          |[arXiv](https://arxiv.org/pdf/2002.00212.pdf) [blog](https://ailabs.tw/human-interaction/pop-music-transformer/) | REMI                                                                                | -                                                                                                                                                                   |
| 2020| [SmallMusicVAE: An encoded latent space model for music variational autoencoder.](https://github.com/Elvenson/midiMe)                                                          |[arXiv](https://research.google/pubs/pub48628/)   | magenta project  -                                                                                | -                                                                                                                                                                   |
| 08.03 | [Structure-Enhanced Pop Music Generation via Harmony-Aware Learning](https://github.com/RMSnow/HAT)                                                          |ACM MM 2022 [arXiv](https://arxiv.org/pdf/2109.06441.pdf) [blog](https://www.zhangxueyao.com/data/HAT/demo.html)        | 1.The repo may be incomplete and some of the code is a bit messy. We will improve in the near future   -                                                                                | -                                                                                                                                                                   |
| 08.03 | [GIGA-Piano-XL](https://github.com/asigalov61/GIGA-Piano-XL)                                                          || SOTA Piano Transformer model (oops!It's not) trained on 4.2GB of Solo Piano MIDI music   -                                                                                | -                                                                                                                                                                   |
| 08.03 | [Orchestrator](https://github.com/asigalov61/Orchestrator)                                                          || Local windowed attention multi-instrumental music transformer tailored for music orchestration/instrumentation and stable music generation-                                                                                | -                                                                                                                                                                   |
| 08.03 | [Euterpe](https://github.com/asigalov61/Euterpe)                                                          || Multi-Instrumental Music Transformer trained on 12GB/400k MIDIs 1) Improvisation 2) Single Continuation 3) Auto-Continuation 4) Inpainting 5) Melody Orchestration  | -|
| 09.02 | ERNIE-Music: Text-to-Waveform Music Generation with Diffusion Models                                                                                                                           | [arXiv](https://arxiv.org/abs/2302.04456)        | -                                                                                | -                                                                                                                                                                   |
| 2023.01.27 | [RAVE2](https://github.com/acids-ircam/RAVE)                    | [arXiv](https://arxiv.org/abs/2111.05011) [blog](https://twitter.com/antoine_caillon/status/1618959533065535491?s=20&t=jMkPWBFuAH19HI9m5Sklmg) [samples](https://anonymous84654.github.io/RAVE_anonymous/)       |                                  | -                                                                                                                                                                   |
| 18.01 | [Msanii: High Fidelity Music Synthesis on a Shoestring Budget](https://kinyugo.github.io/msanii-demo/)                                                                                         | [arXiv](https://arxiv.org/abs/2301.06468)        | [GitHub](https://github.com/Kinyugo/msanii)                                      | [Hugging Face](https://huggingface.co/spaces/kinyugo/msanii) [Colab](https://colab.research.google.com/github/Kinyugo/msanii/blob/main/notebooks/msanii_demo.ipynb) |
| 16.01 | [ArchiSound: Audio Generation with Diffusion](https://flavioschneider.notion.site/Audio-Generation-with-Diffusion-c4f29f39048d4f03a23da13078a44cdb)                                            | [arXiv](https://arxiv.org/abs/2301.13267)        | [GitHub](https://github.com/archinetai/audio-diffusion-pytorch)                  | -                                                                                                                                                                   |
# Accompany  
| Year  | name                                                                                                                                                                              | Paper                                            | Brief | assese                                                          |   
| ----- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 08.03 | [AccoMontage2](https://github.com/billyblu2000/AccoMontage2)                                                          |   ISMIR 2022 [paper](https://arxiv.org/pdf/2209.00353.pdf)      | Chord and accompaniment generator, pure python package that generate chord progression and accompaniment according to given melodies.  | 
| 2023.1.30 | [SingSong: Generating musical accompaniments from singing](https://storage.googleapis.com/sing-song/index.html)                                                          |  [paper](https://arxiv.org/abs/2301.12662)      |  | 

# tools  
| Year  | name                                                                                                                                                                              | Paper                                            | Brief | assese                                                          |   
| ----- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 08.03 | [Automatic Analysis and Influence of Hierarchical Structure on Melody, Rhythm and Harmony in Popular Music](https://github.com/Dsqvival/hierarchical-structure-analysis)                                                          |  CSMC 2021 [paper](https://www.cs.cmu.edu/~rbd/papers/dai-mume2020.pdf)      | use 909pop, 1) a novel algorithm to extract repetition structure at both phrase and section levels from a MIDI data set of popular music, 2) formal evidence that melody, harmony and rhythm are organized to reflect different levels of hierarchy, 3) data-driven models offering new music features and insights for traditional music theory .[more detail](cs.cmu.edu/~music/shuqid/musan.pdf)                                                                             | 

# TTA
| Year  | name                                                                                                                                                                              | Paper                                            | Brief | assese                                                          |   
| ----- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2023.01.30| [AudioLDM: Text-to-Audio Generation with Latent Diffusion Models](https://github.com/haoheliu/AudioLDM)      |[arx](https://arxiv.org/abs/2301.12503) [1](https://audioldm.github.io/) [Hugging Face](https://huggingface.co/spaces/haoheliu/audioldm-text-to-audio-generation)                                                           | Text-to-Audio Generation: Generate audio given text input.Audio-to-Audio Generation: Given an audio, generate another audio that contain the same type of sound.Text-guided Audio-to-Audio Style Transfer: Transfer the sound of an audio into another one using the text description.-                                                                                | 
| 2023.01.30 | [Moûsai: Text-to-Music Generation with Long-Context Latent Diffusion](https://github.com/archinetai/audio-diffusion-pytorch)                                                          |  [arXiv](https://arxiv.org/abs/2301.11757)      | -                                                                                | 
| 2023.02.08 | [Noise2Music: Text-conditioned Music Generation with Diffusion Models](https://google-research.github.io/noise2music/)                                                     |  [arXiv](https://arxiv.org/abs/2302.03917)      | -                                                                                | 
| 2023.02.08 | [MusicLM: Generating Music From Text](https://google-research.github.io/seanet/musiclm/examples/)                                                     |  [paper](https://arxiv.org/abs/2301.11325) [dataset](https://www.kaggle.com/datasets/googleai/musiccaps) [GitHub (unofficial)](https://github.com/lucidrains/musiclm-pytorch)    | -                                                                                | 
| 2023.02.04 | [Multi-Source Diffusion Models for Simultaneous Music Generation and Separation](https://github.com/gladia-research-group/multi-source-diffusion-models)                                                     |  [paper](https://arxiv.org/abs/2302.02257) [blog](https://gladia-research-group.github.io/multi-source-diffusion-models/)     | -                                                                                | 
| 2023.01.29 | [Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models](https://text-to-audio.github.io/)                                                            |  [paper](https://text-to-audio.github.io/paper.pdf) | -                                                                                | 
# dataset
| Year  | name                                                                                                                                                                              | Paper                                            | Brief | assese                                                          |   
| ----- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 08.03 | [Slakh](https://github.com/ethman/slakh-generation)                                                          |  [blog](https://zenodo.org/record/4599666#.ZARG9N9BxPY)      | synthesize large amounts of MIDI data into audio files (1000s of hours) withLakh MIDI Dataset v0.1-                                                                                |
| 08.03 | [Jazznet](https://github.com/tosiron/jazznet)                                                          |        | The jazznet dataset is an extensible dataset containing 162520 labeled 【piano patterns】: chords, arpeggios, scales, and chord progressions, and their inversions in all keys of the 88-key piano.-                                                                                | 
| 08.03 | [pop909](https://github.com/music-x-lab/POP909-Dataset)                                                          |   [paper](https://arxiv.org/pdf/2008.07142.pdf)     |  the vocal melody, the lead instrument melody, and the piano accompaniment for each song in MIDI format aligend.Task 1: Piano accompaniment generation；Task 2: Re-orchestration from audio                                                                               | 伴奏生成，结构化生成可尝试
 
    
    